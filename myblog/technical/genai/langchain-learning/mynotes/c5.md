# ğŸš€ Streamlit Quickstart Guide

> **Streamlit** is a **Python framework for building web applications** with minimal code.

---

## ğŸ§© Installation

Before you start, install the Streamlit package (e.g., in **PyCharm**):

```bash
pip install streamlit
```

---

## ğŸ’» Your First Streamlit App

Hereâ€™s a minimal example that connects **LangChain** and **OpenAI** to Streamlit:

```python
import os
from langchain_openai import ChatOpenAI
import streamlit as st

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
llm = ChatOpenAI(model="gpt-4o", api_key=OPENAI_API_KEY)

st.title("Ask Anything")

question = st.text_input("Enter the question:")

if question:
    response = llm.invoke(question)
    st.write(response.content)
```

---

## ğŸ” Key Concepts

* ğŸŸ¢ Use **`st.text_input()`** instead of `input()`
* ğŸŸ¢ Use **`st.write()`** instead of `print()`
* âš™ï¸ You **canâ€™t run Streamlit apps directly** like normal Python scripts.

### â–¶ï¸ Running Your Streamlit App

1. Open the **terminal** in your project (PyCharm auto-activates your virtual environment).
2. Run your app with:

   ```bash
   streamlit run <filename.py>
   ```

   For example:

   ```bash
   streamlit run streamlit_demo.py
   ```

---

## ğŸª² Debugging Made Easy

To enable detailed debugging, add this:

```python
from langchain import globals
globals.set_debug(True)
```

Now, when you ask a question in the app, detailed logs appear in your terminal.
Youâ€™ll see sections like this:

```json
"llm_output": {
    "token_usage": {
      "completion_tokens": 166,
      "prompt_tokens": 11,
      "total_tokens": 177
    }
}
```

ğŸ’¡ **Pro Tip:**
The `prompt_tokens` value (11 in this example) shows how many **input tokens** were used â€” super useful for tracking **usage and cost**.

---

## ğŸ§  More Debugging Options

If you want to dig deeper, here are additional settings you can play with:

```python
from langchain import globals
```

### ğŸ”ˆ Verbose Mode

* **Set verbose:**

  ```python
  globals.set_verbose(True)
  ```
* **Get verbose:**

  ```python
  verbose = globals.get_verbose()
  ```

### ğŸ§© Debug Mode

* **Set debug:**

  ```python
  globals.set_debug(True)
  ```
* **Get debug:**

  ```python
  debug = globals.get_debug()
  ```

### âš¡ LLM Cache

* **Set cache:**

  ```python
  globals.set_llm_cache(True)
  ```
* **Get cache:**

  ```python
  llm_cache = globals.get_llm_cache()
  ```

---

âœ… **Summary**

Youâ€™ve now learned how to:

* Build and run a **Streamlit web app**
* Connect it with **LangChain + OpenAI**
* Use **debug tools** to understand token usage and model behavior

