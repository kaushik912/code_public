# üöÄ Understanding Sequential Chains with Multiple Inputs in LangChain

In this guide, we‚Äôll explore how to connect multiple prompt chains together ‚Äî where the **output of one prompt becomes the input for another**, and sometimes additional user inputs are also involved.

By the end, you‚Äôll not only understand how this works but also build your own **Marketing Email Generator** app.

---

## üß© Example 1: Regular Sequential Chain with Multiple Inputs

Let‚Äôs look at a practical example ‚Äî a **Speech Generator** app built using Streamlit and LangChain.

```python
import os
from langchain_openai import ChatOpenAI
import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
llm = ChatOpenAI(model="gpt-4o", api_key=OPENAI_API_KEY)

# Step 1: Prompt to generate a title
title_prompt = PromptTemplate(
    input_variables=["topic"],
    template="""You are an experienced speech writer.
    You need to craft an impactful title for a speech 
    on the following topic: {topic}
    Answer exactly with one title.  
    """
)

# Step 2: Prompt to write a speech using the title and emotion
speech_prompt = PromptTemplate(
    input_variables=["title", "emotion"],
    template="""You need to write a powerful {emotion} speech of 350 words
     for the following title: {title}  
     Format the output with 2 keys: 'title','speech' and fill them
     with the respective values  
    """
)

# Step 3: Build the first chain (generates a title)
first_chain = title_prompt | llm | StrOutputParser() | (lambda title: (st.write(title), title)[1])

# Step 4: Build the second chain (writes the speech)
second_chain = speech_prompt | llm | JsonOutputParser()

# Step 5: Combine both chains ‚Äî pass title + emotion as input to second chain
final_chain = first_chain | (lambda title: {"title": title, "emotion": emotion}) | second_chain

# Step 6: Streamlit app interface
st.title("Speech Generator")

topic = st.text_input("Enter the topic:")
emotion = st.text_input("Enter the emotion:")

if topic and emotion:
    response = final_chain.invoke({"topic": topic})
    st.write(response)
    st.write(response['title'])
```

---

### üí° Key Concepts

* **Multiple Inputs to a Chain**

  * The `second_chain` needs **two inputs**:

    * `title`: comes from the first chain‚Äôs output
    * `emotion`: comes directly from user input

* **JSON Output**

  * The speech output is formatted in JSON with two keys ‚Äî `"title"` and `"speech"`.
  * The `JsonOutputParser()` ensures the output is correctly parsed and usable in Python.

* **Chaining Logic**

  ```python
  first_chain = title_prompt | llm | emit_title_from_output
  second_chain = speech_prompt | llm | get_json_output
  final_chain = first_chain | (lambda title: {"title": title, "emotion": emotion}) | second_chain
  ```

  Notice how the `final_chain` combines results from **two sources** ‚Äî the **previous chain** and **user input**.

This pattern is essential whenever your model‚Äôs next step depends on both **previous outputs** and **new inputs**.

---

## ‚úâÔ∏è Assignment: Marketing Email Generator

Now that you understand how multiple inputs work in a sequential chain, let‚Äôs apply it to a real-world task.

Your goal: Build a **Marketing Email Generator** that:

1. Takes a **Product Name**, **Product Features**, and **Target Audience** as inputs.
2. First generates a **catchy subject line**.
3. Then writes a **full marketing email** using that subject line and user inputs.

---

### ‚úÖ Expected Workflow

1. **First Chain**:
   Uses *Product Name* and *Features* to create a subject line.
2. **Second Chain**:
   Takes the *Subject Line*, *Product Name*, and *Target Audience* to generate a complete email.

---

### üíª Sample Solution

```python
from langchain_openai import ChatOpenAI
import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
import os

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o", api_key=OPENAI_API_KEY)

# Step 1: Prompt to generate subject line
product_prompt = PromptTemplate(
    input_variables=["product_name", "features"],
    template="""
    You are an experienced marketing specialist. 
    Create a catchy subject line for a marketing 
    email promoting the following product: {product_name}. 
    Highlight these features: {features}. 
    Respond with only the subject line.
    """
)

# Step 2: Prompt to generate full email
email_prompt = PromptTemplate(
    input_variables=["subject_line", "product_name", "target_audience"],
    template="""
    Write a marketing email of 300 words for the 
    product: {product_name}. Use the subject line:
     {subject_line}. Tailor the message for the 
     following target audience: {target_audience}.
      Format the output as a JSON object with three 
      keys: 'subject', 'audience', 'email' and fill 
      them with respective values.
    """
)

# Step 3: Build the first and second chains
first_chain = product_prompt | llm | StrOutputParser()
second_chain = email_prompt | llm | JsonOutputParser()

# Step 4: Combine both chains
overall_chain = (
    first_chain |
    (lambda subject_line: {"subject_line": subject_line, "product_name": product_name, "target_audience": target_audience}) |
    second_chain
)

# Step 5: Streamlit app interface
st.title("Marketing Email Generator")

product_name = st.text_input("Input Product Name")
features = st.text_input("Input Product Features (comma-separated)")
target_audience = st.text_input("Input Target Audience")

if product_name and features and target_audience:
    response = overall_chain.invoke({"product_name": product_name, "features": features})
    st.write(response)
```

---

### üß† What You Learned

* How to **chain multiple prompts** together in LangChain.
* How to **merge outputs and user inputs** into a single flow.
* How to **use `JsonOutputParser()`** for structured responses.
* How to **integrate LangChain logic inside Streamlit apps** for real-time AI tools.

---

### ‚ú® Pro Tip

Whenever your workflow needs both:

* **Generated context** (like a title or subject line), and
* **External inputs** (like audience or emotion),

think of **sequential chains** ‚Äî they make your LLM pipelines modular, powerful, and easy to debug.
